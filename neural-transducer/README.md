# Neural Transducer

This repo contains a set of neural transducer, e.g. sequence-to-sequence model, focusing on character-level tasks. It powers the following papars and workshop.

[1] Arya D McCarthy, Ekaterina Vylomova, Shijie Wu, Chaitanya Malaviya, Lawrence Wolf-Sonkin, Garrett Nicolai, Miikka Silfverberg, Sebastian J Mielke, Jeffrey Heinz, Ryan Cotterell, and Mans Hulden. [*The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection*](https://www.aclweb.org/anthology/W19-4226/). ACL. 2019.

[Experiments Detail](example/sigmorphon2019-shared-tasks)

[2] Shijie Wu, Ryan Cotterell, and Timothy J O'Donnell. [*Morphological Irregularity Correlates with Frequency*](https://arxiv.org/abs/1906.11483). ACL. 2019.

[Experiments Detail](example/irregularity-acl19)

[3] Shijie Wu, and Ryan Cotterell. [*Exact Hard Monotonic Attention for Character-Level Transduction*](https://arxiv.org/abs/1905.06319). ACL. 2019.

[Experiments Detail](example/hard-monotonic-attention-acl19)

[4] Chaitanya Malaviya *, Shijie Wu *, and Ryan Cotterell. [*A Simple Joint Model for Improved Contextual Neural Lemmatization*](https://arxiv.org/abs/1904.02306). NAACL. 2019.

\* Equal contribution. Order has been determined with a coin flip.

[Experiments Detail](example/lemmatization-naacl19)

[5] Shijie Wu, Pamela Shapiro, and Ryan Cotterell. [*Hard Non-Monotonic Attention for Character-Level Transduction*](https://arxiv.org/abs/1808.10024). EMNLP. 2018.


[Experiments Detail](example/hard-attention-emnlp18)


## Dependencies

- python 3
- pytorch
- numpy
- tqdm
- fire

## License

MIT
